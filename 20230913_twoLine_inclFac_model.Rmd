---
title: "20230905_twoLine_model.R"
output:
  html_document:
    df_print: paged
date: "2023-09-05"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Two-line model

Assume a model where the percentage of disease changes according to the addition of two lines. The first has a rate \>= 0, the second with a rate \<= 0 starts at some time after the initial time point of the first line.

(Currently, both lines use a first-order rate; an alternative model would be that the second effect depends on level at the given time point)

```{r cars}
rm(list=ls())
cat('\014')
graphics.off()

suppressWarnings({      #no warnings to avoid cluttering Knit
library('tidyverse',quietly=TRUE,warn.conflicts = FALSE,verbose=FALSE) 
library('rjags')
source('./DBDA2E-utilities_mod.R')  #modified to fit markdown
source('./20230912_twoLine_inclFac_fit.R')
})
```

## Model visualization and SSQ parameter estimate

```{R}
set.seed(01092023)

#testCase= c(a0=2, a1=1, a2= -1.5, t0=40, noiseSD= 0.1)
#testCase= c(a0=2, a1=1, a2= -0.05,t0=40, noiseSD= 0.1)
#testCase= c(a0=2, a1=-1, a2= 0.5,t0=40, noiseSD= 0.1)
#testCase= c(a0=2, a1=-0.1, a2= 0.5,t0=40, noiseSD= 0.1)
testCase= c(a0=2, a1=1, a2= -0.5,t0=40, noiseSD= 0.3)
a0= testCase[1]; a1=testCase[2]; a2= testCase[3]
t0= testCase[4]
noiseSD= testCase[5]

t= 0:100

y_noNoise= a0 + a1*t + a2*ifelse(t>t0,t-t0,0)
#noise1= rnorm(length(t),mean=0,sd=1)  #constant noise level
noise2= rnorm(length(t),mean=0,sd=noiseSD*abs(y_noNoise))  #noise relative to data
y= y_noNoise+noise2
y[y<0]= 0   #make sure no negative values
DF= cbind.data.frame(t=t,y=y)

plot(t,y,ylim=c(0,1.1*max(y)))

twoLine_fun= function(t, pms, obs){  #ssq minimization between observed data
                                       #and two-line model
  a0= pms[1]; a1=pms[2]; a2=pms[3]; t0= pms[4]
  y= a0 + a1*t + a2*ifelse(t>t0,t-t0,0)
  
  ssq= sum( (obs-y)^2 )
  return(ssq)
}

pms= c(a0,a1,a2,t0)
#twoLine_fun(t,pms,obs=y)

nlmOUT= nlm(f=twoLine_fun,p=c(a0=0,a1=1,a2=1,t0=max(t)/2),t=t,obs=y)
est= nlmOUT$estimate

lines(t, est[1] + est[2]*t + est[3]*ifelse(t>est[4],t-est[4],0),col='blue')
```

# Estimate parameters based on Bayesian model
```{R}
DF1= twoLine_fit(t=t,y=y)
head(DF1)
```

```{R}
# MCMC results
par(mfrow=c(2,2))
hist(DF1$b0,col='skyblue',breaks=50)
lines(x=HDIofMCMC(DF1$b0,credMass=.95),y=c(0,0),lwd=5)

hist(DF1$b1,col='skyblue',breaks=50)
lines(x=HDIofMCMC(DF1$b1,credMass=.95),y=c(0,0),lwd=5)

hist(DF1$b2,col='skyblue',breaks=50)
lines(x=HDIofMCMC(DF1$b2,credMass=.95),y=c(0,0),lwd=5)

hist(DF1$t0,col='skyblue',breaks=50)
lines(x=HDIofMCMC(DF1$t0,credMass=.95),y=c(0,0),lwd=5)


par(mfrow=c(1,1))
plot(DF1$b1,DF1$b2,col='skyblue')

par(mfrow=c(1,2))
hist(DF1$iF1,xlim=c(-.2,1.2),breaks=seq(-0.1,1.1,.2),col='skyblue',xaxt='n')
axis(side=1, at=c(0,1), labels=c(0,1))
hist(DF1$iF2,xlim=c(-.2,1.2),breaks=seq(-0.1,1.1,.2),col='skyblue',xaxt='n')
axis(side=1, at=c(0,1), labels=c(0,1))
```

```{R}
# Posterior prediction
n= 20
y_pred= matrix(NA,nrow=n,ncol=length(t))
pred_idx= sample(1:dim(DF1)[1],size=n)  #posterior prediction for n values
for(i in 1:length(pred_idx)){
  #print(paste(i))
  y_pred[i,]= DF1$b0[i] + DF1$iF1[i]*DF1$b1[i]*t + ifelse(DF1$t0[i]>=t,DF1$iF2[i]*DF1$b2[i]*(t-DF1$t0[i]),0)
}
plot(type='n',x=t,y=rep(0,length(t)),ylim=c(0,max(y_pred)))
for(i in 1:dim(y_pred)[1]){
  lines(t,y_pred[i,])
}
```

# Test prediction power for some simulated data
 (no systematic evaluation)
## Rate constants different from 0 (evaluate sensitivity)
```{R}
a0=2
t= 0:30 #match the actual data: 1 measurement per year for 30 years
t0= 20
coefDF= expand.grid(a1=c(0.01,0.1,1), a2=c(-.01,-.1,-0.5))   #a1>0, a2<0


#dev.new(width=12,height=12,noRStudioGD = TRUE)
par(mfrow=c(nrow=ceiling(dim(coefDF)[1]/3),ncol=3),mar=c(3,3,1,0))
DF_result= data.frame(matrix(NA,nrow=dim(coefDF)[1],ncol=8))
colnames(DF_result)= c('b1','b2','b1_correct','b2_correct','b1_relErr', 'b2_relErr','est_b1','est_b2')
for(i in 1:dim(coefDF)[1]){  
  a1= coefDF$a1[i]; a2= coefDF$a2[i]
  DF_result[i,c(1,2)]= c(a1,a2)
  y_noNoise= a0 + a1*t + a2*ifelse(t>t0,t-t0,0)
  noise= rnorm(length(t),mean=0,sd=0.1*abs(y_noNoise))  #noise relative to data
  y= y_noNoise+noise
  y[y<0]= 0   #make sure no negative values
  plot(t,y,ylim=c(0,1.1*max(y)),main=paste('b1:',a1,', b2:',a2)) #change naming: 'a' are simulated, 'b' estimated params
  
  DF1= twoLine_fit(t,y)
  
  #There are two coefficients (b1, b2) that each can either be present of absent as indicated by indicator factors
  DF1$iF1= factor(DF1$iF1, levels=c(0,1)) #to make sure both levels are listed even if only one observed
  DF1$iF2= factor(DF1$iF2, levels=c(0,1))
  tab2Way= data.table(table(cbind.data.frame(iF1=DF1$iF1, iF2=DF1$iF2)))
   #find the most frequent combination of indicator factors -> the best model
  iF1_best= tab2Way$iF1[tab2Way$N==max(tab2Way$N)]
  iF2_best= tab2Way$iF2[tab2Way$N==max(tab2Way$N)]
  
  b1_correct= ifelse( a1>0 & iF1_best==1 | a1==0 & iF1_best==0, 1, 0)
  b2_correct= ifelse( a2<0 & iF2_best==1 | a2==0 & iF2_best==0, 1, 0)
  
  #select the coefficients only from the best model
  b1_selec= DF1$b1[DF1$iF1==iF1_best & DF1$iF2==iF2_best]
  b2_selec= DF1$b2[DF1$iF1==iF1_best & DF1$iF2==iF2_best]
  
  b1_relErr= abs(mean(b1_selec)-a1+1E-5)/abs(a1+1E-3)  #relative error of mean estimate; w. flooring
  b2_relErr= abs(mean(b2_selec)-a2+1E-5)/abs(a2+1E-3)  #relative error of mean estimate; w. flooring
  DF_result[i,3:8]= c(b1_correct,b2_correct,b1_relErr,b2_relErr,median(DF1$b1),median(DF1$b2))

  lines(t, mean(DF1$b0) + mean(DF1$b1)*t + mean(DF1$b2) *ifelse(t>mean(DF1$t0),t-mean(DF1$t0),0), col='blue')
}

#manually reformat
DF_result_long= cbind.data.frame(
  coef= c(DF_result$b1,DF_result$b2),
  estCoef= c(DF_result$est_b1,DF_result$est_b2),
  x= factor(c(rep(1,dim(DF_result)[1]),rep(2,dim(DF_result)[1])),levels=c(1,2)),
  y= rep(1:dim(DF_result)[1],times=2),
  correct= factor(c(DF_result$b1_correct,DF_result$b2_correct),levels=c(0,1)),
  relErr= c(DF_result$b1_relErr,DF_result$b2_relErr)
  )

ggplot()+
  geom_point(data=DF_result_long,aes(x=x,y=y,color=correct,size=relErr))+  #log10_recipRelErr
  scale_color_manual(limits=as.character(c(0,1)),values=c('red','green'),labels=c('no','yes'))+
  scale_size_continuous(trans='log10')+
  geom_text(data=DF_result_long,aes(x=as.numeric(x)-0.2,y=y, label=coef))+
  theme_minimal()+
  scale_x_discrete(breaks=c(1,2),labels=c('b1','b2'))+
  theme(axis.title= element_blank(),axis.text.y=element_blank())
```

At a noise level of SD = 10%, a rate or 0.01 / -0.01 percent/year is generally
not detectable. Decline rates can also be undetected if decline starts at relatively high percentage, because noise is modeled relative. The prediction successes correspond to cases where also visually a correct prediction could be made.
The relative errors are generally indicative of prediction success.
Note that start of decline was fixed to 20th of the 30 years; changing this
choice and changing assumed variation will alter estimation power.

## At least one rate constant == 0 (evaluate selectivity)
```{R}
a0=2
t= 0:30 #match the actual data: 1 measurement per year for 30 years
t0= 20
coefDF= data.frame(
  a1= c(0, 0.,  0.01,0.1),
  a2= c(0,-0.01,0,   0)
)   #a1>=0, a2<=0


#dev.new(width=12,height=12,noRStudioGD = TRUE)
par(mfrow=c(nrow=ceiling(dim(coefDF)[1]/2),ncol=2),mar=c(3,3,1,0))
DF_result= data.frame(matrix(NA,nrow=dim(coefDF)[1],ncol=8))
colnames(DF_result)= c('b1','b2','b1_correct','b2_correct','b1_relErr', 'b2_relErr','est_b1','est_b2')
for(i in 1:dim(coefDF)[1]){  
  a1= coefDF$a1[i]; a2= coefDF$a2[i]
  DF_result[i,c(1,2)]= c(a1,a2)
  y_noNoise= a0 + a1*t + a2*ifelse(t>t0,t-t0,0)
  noise= rnorm(length(t),mean=0,sd=0.1*abs(y_noNoise))  #noise relative to data
  y= y_noNoise+noise
  y[y<0]= 0   #make sure no negative values
  plot(t,y,ylim=c(0,1.1*max(y)),main=paste('b1:',a1,', b2:',a2)) #change naming: 'a' are simulated, 'b' estimated params
  
  DF1= twoLine_fit(t,y)
  
  #There are two coefficients (b1, b2) that each can either be present of absent as indicated by indicator factors
  DF1$iF1= factor(DF1$iF1, levels=c(0,1)) #to make sure both levels are listed even if only one observed
  DF1$iF2= factor(DF1$iF2, levels=c(0,1))
  tab2Way= data.table(table(cbind.data.frame(iF1=DF1$iF1, iF2=DF1$iF2)))
   #find the most frequent combination of indicator factors -> the best model
  iF1_best= tab2Way$iF1[tab2Way$N==max(tab2Way$N)]
  iF2_best= tab2Way$iF2[tab2Way$N==max(tab2Way$N)]
  
  b1_correct= ifelse( a1>0 & iF1_best==1 | a1==0 & iF1_best==0, 1, 0)
  b2_correct= ifelse( a2<0 & iF2_best==1 | a2==0 & iF2_best==0, 1, 0)
  
  #select the coefficients only from the best model
  b1_selec= DF1$b1[DF1$iF1==iF1_best & DF1$iF2==iF2_best]
  b2_selec= DF1$b2[DF1$iF1==iF1_best & DF1$iF2==iF2_best]
  
  b1_relErr= abs(mean(b1_selec)-a1+1E-5)/abs(a1+1E-3)  #relative error of mean estimate; w. flooring
  b2_relErr= abs(mean(b2_selec)-a2+1E-5)/abs(a2+1E-3)  #relative error of mean estimate; w. flooring
  DF_result[i,3:8]= c(b1_correct,b2_correct,b1_relErr,b2_relErr,median(DF1$b1),median(DF1$b2))
  
  lines(t, mean(DF1$b0) + mean(DF1$b1)*t + mean(DF1$b2) *ifelse(t>mean(DF1$t0),t-mean(DF1$t0),0), col='blue')
}

#manually reformat
DF_result_long= cbind.data.frame(
  coef= c(DF_result$b1,DF_result$b2),
  estCoef= c(DF_result$est_b1,DF_result$est_b2),
  x= factor(c(rep(1,dim(DF_result)[1]),rep(2,dim(DF_result)[1])),levels=c(1,2)),
  y= rep(1:dim(DF_result)[1],times=2),
  correct= factor(c(DF_result$b1_correct,DF_result$b2_correct),levels=c(0,1)),
  relErr= c(DF_result$b1_relErr,DF_result$b2_relErr),
  log10_recipRelErr= log(1/c(DF_result$b1_relErr,DF_result$b2_relErr),10) #log10 of recip. relErr
)

ggplot()+
  geom_point(data=DF_result_long,aes(x=x,y=y,color=correct,size=relErr))+  
  scale_color_manual(limits=as.character(c(0,1)),values=c('red','green'),labels=c('no','yes'))+
  scale_size_continuous(trans='log10')+
  geom_text(data=DF_result_long,aes(x=as.numeric(x)-0.2,y=y, label=coef))+
  theme_minimal()+
  scale_x_discrete(breaks=c(1,2),labels=c('b1','b2'))+
  theme(axis.title= element_blank(),axis.text.y=element_blank())
```

At a noise level of SD = 10%, the parameter estimation did not make any false
positive errors at true rates = 0.